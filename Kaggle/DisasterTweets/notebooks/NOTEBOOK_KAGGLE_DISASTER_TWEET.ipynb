{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPo5kCCNgeGdfKdkBaENH63",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidMichaelH/machine-learning/blob/main/Kaggle/DisasterTweets/notebooks/NOTEBOOK_KAGGLE_DISASTER_TWEET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Kaggle Disaster Tweets**"
      ],
      "metadata": {
        "id": "fIstEV7Xwl5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we aim to achieve a high accuracy in the Kaggle Disaster Tweets competition by utilizing feature engineering techniques to improve the performance of a **logistic regression mode**l. We will then compare the results with a more sophisticated model like **Long-Short Term Memory (LSTM)** to see if a higher score can be achieved.\n",
        "\n",
        "\n",
        "You should expect to see at least $\\textbf{79%}$ validation accuracy for the **logistic regression model** and $\\textbf{>80%}$ for the **LSTM model** by running the notebook as is.  "
      ],
      "metadata": {
        "id": "9mJcUXclqm46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Kaggle Disaster Tweets](#scrollTo=fIstEV7Xwl5z)\n",
        "\n",
        ">>[Problem statement and objectives](#scrollTo=ngF6RA5sNZK1)\n",
        "\n",
        ">[Setting up Kaggle Environment and Downloading the Competition Data](#scrollTo=dwrUhBv-FV0H)\n",
        "\n",
        ">[Exploratory Data Analysis](#scrollTo=MQ_aak1pFay2)\n",
        "\n",
        ">[Text Feature Extraction](#scrollTo=pjl9cUy5H1F4)\n",
        "\n",
        ">[Model Selection and Evaluation](#scrollTo=zElcrAG-Fl2o)\n",
        "\n",
        ">[Evaluate the Performance of the Model](#scrollTo=tFv2TleuFowM)\n",
        "\n",
        ">[Deep Learning Approach](#scrollTo=-q2aX63zjclO)\n",
        "\n",
        ">[Word Embeddings](#scrollTo=aWtfYdkDS9KB)\n",
        "\n",
        ">[Deep Learning Models](#scrollTo=7DC6KNFgoXl6)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "cq9B-XJVzRNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem statement and objectives\n",
        "\n",
        "Problem statement:\n",
        "In the event of a disaster, people often turn to social media to share information and updates. However, sorting through these tweets and identifying the relevant information can be a time-consuming and challenging task. The goal of this project is to develop a model that can accurately classify tweets as disaster-related or not, to help emergency responders quickly identify and respond to crisis situations.\n",
        "\n",
        "Objectives:\n",
        "\n",
        "*  Develop a model that can accurately classify tweets as disaster-related or not\n",
        "*  Preprocess and clean the tweets to remove irrelevant information\n",
        "*  Extract features from the tweets to improve model performance\n",
        "*  Train and evaluate the model using a combination of traditional machine learning and deep learning techniques\n",
        "*  Improve the model's performance by optimizing the parameters\n",
        "*  Evaluate the model's performance using metrics such as accuracy, precision, recall, and F1 score.\n",
        " \n"
      ],
      "metadata": {
        "id": "ngF6RA5sNZK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Sklearn imports\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import StratifiedKFold,KFold\n",
        "\n",
        "# NLTK imports\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "from nltk import FreqDist, word_tokenize\n",
        "\n",
        "# Wordcloud import\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# Keras imports\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils, pad_sequences\n",
        "\n",
        "# Plotting library\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "\n",
        "\n",
        "# String manipulation \n",
        "import string\n",
        "import re\n",
        "\n",
        "\n",
        "! pip install category_encoders\n",
        "import category_encoders as ce"
      ],
      "metadata": {
        "id": "0w8Uq-k9JqkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining a list of english stopwords from the nltk corpus \n",
        "stop_words = stopwords.words('english') "
      ],
      "metadata": {
        "id": "OV1OWv8xLdFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Kaggle Environment and Downloading the Competition Data"
      ],
      "metadata": {
        "id": "dwrUhBv-FV0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install and upgrade kaggle library"
      ],
      "metadata": {
        "id": "Fs53IysOHsHH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sfuDZ5Pr50r"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "!pip install kaggle --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the json file used to autheticate with kaggle."
      ],
      "metadata": {
        "id": "Y_E5K0TgsS2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "yBV170GFsSIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the directory where you will store the json file."
      ],
      "metadata": {
        "id": "hwBxmgwZsdE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "78-q_on7sgOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the kaggle file into the new directory. This is where kaggle expects to find the file."
      ],
      "metadata": {
        "id": "Mn53VddksiGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "w80Gfladshdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elevate the file permissions so it can be modified."
      ],
      "metadata": {
        "id": "eFY3_JtSsnU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "pl7jIVv1smug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "download the kaggle file"
      ],
      "metadata": {
        "id": "UljTdY36ImY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c nlp-getting-started"
      ],
      "metadata": {
        "id": "5OYTyjFUsGmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "unzip the files"
      ],
      "metadata": {
        "id": "4ertmQZ4w3V2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip nlp-getting-started.zip"
      ],
      "metadata": {
        "id": "mCXTc25xsJIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mv train.csv labled_data.csv"
      ],
      "metadata": {
        "id": "hDTLgkDTNDOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mv test.csv unlabled_data.csv"
      ],
      "metadata": {
        "id": "mKgQEP8MNKgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Use pandas to load the data into a dataframe. Perform some initial cleaning and preprocessing of the data, such as removing missing values and duplicates."
      ],
      "metadata": {
        "id": "x2eJnYFh1cDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labled = pd.pandas.read_csv(\"labled_data.csv\")\n",
        "unlabled = pd.pandas.read_csv(\"unlabled_data.csv\")\n",
        "sample = pd.pandas.read_csv(\"sample_submission.csv\")"
      ],
      "metadata": {
        "id": "TmekAipF1evm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis\n",
        "\n",
        "Conduct an exploratory data analysis (EDA) to understand the distribution of the target variable, identify any missing values, and create visualizations for insight."
      ],
      "metadata": {
        "id": "MQ_aak1pFay2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step is to view some of the labeled data examples."
      ],
      "metadata": {
        "id": "4qTuAleL_Kln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labled.head(20)"
      ],
      "metadata": {
        "id": "2_Vf6hp9_PD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code cell randomly selects and prints a row from the labeled data set along with its corresponding text."
      ],
      "metadata": {
        "id": "G-cWeM6cAM0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = np.random.randint(0,len(labled))\n",
        "print( labled.iloc[index])\n",
        "print(labled.text[index])"
      ],
      "metadata": {
        "id": "x0-yXURY_UAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We look at the distribution of the target variable to understand how many of each type we have. This will be useful to gauge whether we have a balanced set of example, each category should have a sufficiently representative sample."
      ],
      "metadata": {
        "id": "Iq_IDE0jA1JI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(y=labled.target);"
      ],
      "metadata": {
        "id": "Kfw9QuNpBEzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These code cells calculates and prints the percentage of missing values in each column of both labeled and unlabeled data sets."
      ],
      "metadata": {
        "id": "mSvvvxQBBN3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Percetange of null entries in training set\")\n",
        "print(\"-\"*30)\n",
        "labled.isnull().sum()/len(labled)"
      ],
      "metadata": {
        "id": "13aGlM6wBNe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Percetange of null entries in test set\")\n",
        "print(\"-\"*30)\n",
        "unlabled.isnull().sum()/len(unlabled)"
      ],
      "metadata": {
        "id": "s8mAWBcKBp8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploring the Keyword Feature**"
      ],
      "metadata": {
        "id": "UfyxYF5IjEtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the number of unique keywords in the training and test sets."
      ],
      "metadata": {
        "id": "dENIp34XEQqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(labled.keyword.nunique(), unlabled.keyword.nunique())"
      ],
      "metadata": {
        "id": "6uUegj1SEJm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The keywords are an interesting feature in this dataset. So we begin by examining them closely.\n",
        "\n",
        "We can obtain a sorted dataframe consiting of keywords and their number of occurances using the follow panda operations"
      ],
      "metadata": {
        "id": "rHuIyu_eDaeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labled.keyword.value_counts().head(10)"
      ],
      "metadata": {
        "id": "nJPMdZUKDXH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code cell displays the top 15 most frequently occurring keywords in the training set."
      ],
      "metadata": {
        "id": "NyB_VGfczmqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labled.keyword.value_counts().iloc[:15]"
      ],
      "metadata": {
        "id": "bY64kw2_Pw2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can perhaps better illustrate their frequency by ploting the first 15. \n",
        "\n",
        "This is the top 15 keywords including both disaster and non-disaster related tweets. "
      ],
      "metadata": {
        "id": "iqVDogriC0v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_top_values(series,plot_name,top_num=15):\n",
        "  top_num = min(top_num,len(series))\n",
        "  plt.figure(figsize=(9,6))\n",
        "  sns.countplot(y=series, order = series.value_counts().iloc[:top_num].index)\n",
        "  plt.title(plot_name)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Wmi-5r3PYyv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the top 15 keywords in the training set. "
      ],
      "metadata": {
        "id": "lfZJakVvHeYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kw = labled.keyword\n",
        "plot_top_values(kw,'Top 15 keywords')"
      ],
      "metadata": {
        "id": "igmERtcKaB64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separate disaster and non-disaster related tweets and display the top 15 keywords for each."
      ],
      "metadata": {
        "id": "B41Abi7Ehy4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kw = labled[labled.target == 1].keyword;\n",
        "plot_top_values(kw,'Top 15 Disaster keywords')"
      ],
      "metadata": {
        "id": "egJPlzcBEYH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kw = labled[labled.target == 0].keyword;\n",
        "plot_top_values(kw,'Top 15 Non-Disaster keywords')"
      ],
      "metadata": {
        "id": "DwkbUo0eEqXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would like to know how the keyword might help us to decide the if the tweet corresponds to a disaster or not. They way might try to measure that is by taking averages over the target values for each particular keyword. "
      ],
      "metadata": {
        "id": "wcpNgSo1EYV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_features(df,top_num_to_disp,feature_name,min_num_examples = 1,target_name = 'target',ascending=False,plot_title = ''):\n",
        "    \"\"\"\n",
        "    This function is used to display the mean target value of the top N features, and plots them in a bar chart.\n",
        "    The function takes in the following parameters:\n",
        "    df : DataFrame - The dataframe containing the data to be plotted\n",
        "    top_num_to_disp : int - The number of top features to display\n",
        "    feature_name : str - The name of the feature column to groupby and display\n",
        "    min_num_examples : int - The minimum number of examples for a feature to be included in the display\n",
        "    target_name : str - The name of the target column to display the mean of\n",
        "    ascending : bool - Order to sort the feature values by (default is False, descending)\n",
        "    plot_title : str - Title for the plot (default is empty)\n",
        "    \"\"\"\n",
        "    raw_loc = labled[feature_name].value_counts() # Get the raw counts of the feature values\n",
        "    top_loc = list(raw_loc[raw_loc>=min_num_examples].index) # Get the top features that have at least min_num_examples\n",
        "    top_only = labled[labled[feature_name].isin(top_loc)] # Filter the dataframe to only include the top features\n",
        "\n",
        "    df = top_only.groupby(feature_name).mean()[target_name].sort_values(ascending=ascending) # groupby feature and calculate mean of target\n",
        "\n",
        "    plt.figure(figsize=(20,14)) # set the size of the plot\n",
        "    # Create a bar plot of the top number of features to display\n",
        "    sns.barplot(x=df.iloc[:top_num_to_disp].index, y=df.iloc[:top_num_to_disp])\n",
        "    # Draw a line at the mean target value\n",
        "    plt.axhline(np.mean(labled[target_name]))\n",
        "    plt.xticks(rotation=80)\n",
        "    if len(plot_title) > 0:\n",
        "        plt.title(plot_title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2wjvEvEkvBmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the top 30 keywords that are most likely to be disaster tweets"
      ],
      "metadata": {
        "id": "h-ZzR2XwLzBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_features(labled,30,'keyword',min_num_examples= 10,ascending=False,plot_title='Keywords with highest % of disaster tweets')"
      ],
      "metadata": {
        "id": "pBzVisYJ2Gjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the top 30 keywords that are least likely to be disaster tweets"
      ],
      "metadata": {
        "id": "BR3voK6zMD3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_features(labled,30,'keyword',min_num_examples= 10,ascending=True,plot_title='Keywords with highest % of non-disaster tweets')"
      ],
      "metadata": {
        "id": "iDamMuZKyPFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploring the Location Feature in Disaster Tweets**"
      ],
      "metadata": {
        "id": "JorcDveTjKUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this analysis is to understand the distribution of unique locations in the labeled and unlabeled datasets, as well as the relationship between location and disaster tweets."
      ],
      "metadata": {
        "id": "Ir_r4QXfJPHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of unique locations\n",
        "print(\"Number of unique locations in labeled dataset:\", labled.location.nunique())\n",
        "print(\"Number of unique locations in unlabeled dataset:\", unlabled.location.nunique())"
      ],
      "metadata": {
        "id": "5M0kTZrwK41M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a better understanding of the distribution of locations in the labeled dataset, let's examine the top 15 locations."
      ],
      "metadata": {
        "id": "CNM0OS_wjnfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the most common locations among the labeled dataset\n",
        "kw = labled.location\n",
        "plot_top_values(kw, 'Top 15 locations')\n"
      ],
      "metadata": {
        "id": "LgOK-UoqMJfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's see which of the top locations are most common among disaster tweets."
      ],
      "metadata": {
        "id": "qOp6quLK3i3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the top locations among disaster tweets\n",
        "display_features(labled,10,'location',min_num_examples= 10,ascending=False,plot_title='Locations with highest % of disaster tweets')"
      ],
      "metadata": {
        "id": "5OjhS06CjhFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And conversely, let's examine which of the top locations are most common among non-disaster tweets."
      ],
      "metadata": {
        "id": "oo5cXAme3wUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the top locations among non-disaster tweets\n",
        "display_features(labled,10,'location',min_num_examples= 10, ascending=True,plot_title='Locations with highest % of non-disaster tweets')"
      ],
      "metadata": {
        "id": "49WS6jTI3Bm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's see which locations are most commonly used in disaster and non-disaster tweets, respectively."
      ],
      "metadata": {
        "id": "UjFqt2dy4ScI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the top disaster locations\n",
        "kw = labled[labled.target == 1].location\n",
        "plot_top_values(kw, 'Top 15 Disaster locations')\n",
        "\n",
        "# Examine the top non-disaster locations\n",
        "kw = labled[labled.target == 0].location\n",
        "plot_top_values(kw, 'Top 15 Non-Disaster locations')\n"
      ],
      "metadata": {
        "id": "K6-_inRlVK5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Feature Extraction\n",
        "\n",
        " Perform cleaning and preprocessing of the data, such as removing missing values and duplicates."
      ],
      "metadata": {
        "id": "pjl9cUy5H1F4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the number of duplicated items in the training set"
      ],
      "metadata": {
        "id": "yQjK4_z5CWGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicates in the training set\n",
        "print(\"Number of duplicates:\", labled.duplicated().sum())\n",
        "\n",
        "# Remove duplicates, if any\n",
        "labled = labled.drop_duplicates().reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "r9fNBivfCTqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create some functions to help us clean up the text while recording any potentially useful information in a new column to make sure we don't throw any valuable information away."
      ],
      "metadata": {
        "id": "Bh25iGea5wkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define stop words\n",
        "STOP_WORDS = set(stop_words)\n",
        "\n",
        "# Remove newlines, extra white space, and hyperlinks from text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text).strip()\n",
        "    text = re.sub(r'https?://\\S+', '', text)\n",
        "    return text\n",
        "\n",
        "# Test the function\n",
        "test_str = \"A man went to https://www.google.com/ and \\n looked up a dog wearing a hat!\"\n",
        "print(\"Original text:\", test_str)\n",
        "print(\"Cleaned text:\", clean_text(test_str))"
      ],
      "metadata": {
        "id": "vpu4uWw_TjAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words, lowercase the text, remove hashtags and mentions from text\n",
        "def process_text(text):\n",
        "    text = re.sub(r'#','', text)\n",
        "    text = re.sub(r'@','', text)\n",
        "    words = word_tokenize(text)\n",
        "    text = \" \".join([word for word in words if word.lower() not in STOP_WORDS])\n",
        "    text = text.lower()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Test the function\n",
        "test_str = \"I love #dogs and @cats!\"\n",
        "print(\"Original text: \" + test_str)\n",
        "print(\"Cleaned text: \" + process_text(test_str))"
      ],
      "metadata": {
        "id": "XuvdezY91ZEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract tokens matching a regular expression from text\n",
        "def find_reg_ex(tweet, reg_ex):\n",
        "    tokens = re.finditer(reg_ex, tweet)\n",
        "    token_list = []\n",
        "    for match in tokens:\n",
        "        token = match.group(0)\n",
        "        token_list.append(token)\n",
        "    if len(token_list) == 0:\n",
        "        return 'no'\n",
        "    else:\n",
        "        return \" \".join(token_list)\n",
        "\n",
        "# Find hashtags in text\n",
        "def find_hashtags(tweet):\n",
        "    hashtags = re.finditer(r\"#\\w+\", tweet)\n",
        "    hashtags = [match.group(0)[1:] for match in hashtags]\n",
        "    return \" \".join(hashtags) or 'no'\n",
        "\n",
        "# Extract various features from text\n",
        "def extract_text_features(df):\n",
        "    df['text_clean'] = df['text'].apply(lambda x: clean_text(x))\n",
        "    df['hashtags'] = df['text'].apply(lambda x: find_hashtags(x)) # hashtags\n",
        "    df['mentions'] = df['text'].apply(lambda x: find_reg_ex(x,r\"@\\w+\")) # mentions\n",
        "    df['links'] = df['text'].apply(lambda x: find_reg_ex(x,r\"https?://\\S+\")) # links    \n",
        "    df['text_len'] = df['text_clean'].apply(len) # Tweet length    \n",
        "    df['word_count'] = df[\"text_clean\"].apply(lambda x: len(str(x).split())) # Word count   \n",
        "    df['stop_word_count'] = df['text_clean'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS])) # Stopword count    \n",
        "    df['punctuation_count'] = df['text_clean'].apply(lambda x: len([c for c in str(x) if c in string.punctuation])) # Punctuation count    \n",
        "    df['hashtag_count'] = df['hashtags'].apply(lambda x: len(str(x).split())) # Count of hashtags (#)    \n",
        "    df['mention_count'] = df['mentions'].apply(lambda x: len(str(x).split())) # Count of mentions (@)    \n",
        "    df['link_count'] = df['links'].apply(lambda x: len(str(x).split())) # Count of links  \n",
        "    df['caps_count'] = df['text_clean'].apply(lambda x: sum(1 for c in str(x) if c.isupper())) # Count of uppercase letters\n",
        "    df['caps_ratio'] = df['caps_count'] / df['text_len'] # Ratio of uppercase letters\n",
        "    df['text_clean'] = df['text_clean'].apply(lambda x: process_text(x))\n",
        "    return df\n",
        " \n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "kxsiSdjT6HEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After some processing, we will extract features from the text data and add them as new columns to the dataframe. We'll use the function `extract_text_features` to process the `labled` and `unlabled` dataframes:\n",
        "\n"
      ],
      "metadata": {
        "id": "vJSkz9RDZTrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labled = extract_text_features(labled) \n",
        "unlabled = extract_text_features(unlabled) \n",
        "\n",
        "print(\"The shapes of the labled and unlabled dataframes are:\", labled.shape, unlabled.shape)"
      ],
      "metadata": {
        "id": "BEaLxTda1wSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we measure the linear correlation between the columns and the target Next, we measure the linear correlation between the columns and the target value. However, the results don't show a strong positive correlation. The column `id` ranks second, which is expected to be meaningless. The `stop_word_count` might have some significance, but it's unclear. It's possible that a tweet with many filler words may not be particularly urgent, but this is just speculation.\n",
        "\n"
      ],
      "metadata": {
        "id": "V8sGQ-0W7odO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_df = labled.corr()['target'].drop('target').sort_values()\n",
        "print(\"Linear correlation between columns and target: \\n\", corr_df)"
      ],
      "metadata": {
        "id": "E41TdZ_a7VQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of interest, only the `text_len` and `stop_word_count` appear to have a significant correlation. These columns might be included in the final set of features and the others ignored.\n"
      ],
      "metadata": {
        "id": "txc1Wi0jrxGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_words_frequency_bar_plot(text,ax = None,plot_title='',num_top_words = 20):\n",
        "  tokens = word_tokenize(text)\n",
        "\n",
        "  # Remove stopwords and non-alphabetic characters from the tokenized text\n",
        "  filtered_tokens = [w for w in tokens if (w not in STOP_WORDS) & (w.isalpha())]\n",
        "\n",
        "  # Count the frequency of each word\n",
        "  word_freq = FreqDist(filtered_tokens)\n",
        "\n",
        "  # Convert the word frequency to a dataframe\n",
        "  df_word_freq = pd.DataFrame.from_dict(word_freq, orient='index', columns=['count'])\n",
        "\n",
        "  # Select the top 20 words based on frequency count\n",
        "  top20w = df_word_freq.sort_values('count',ascending=False).head(num_top_words)\n",
        "\n",
        "  # Create a bar plot of the top 20 words\n",
        " \n",
        "  if ax is None:\n",
        "    # Create a figure and axes object\n",
        "    fig, ax = plt.subplots(figsize=(8,6))\n",
        "\n",
        "  sns.barplot(top20w['count'], top20w.index,ax = ax)\n",
        "  ax.set_title(plot_title)"
      ],
      "metadata": {
        "id": "NpUCDiVZ_QmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(labled['text_clean']).lower()\n",
        "top_words_frequency_bar_plot(text)"
      ],
      "metadata": {
        "id": "X1BjuuiIBy4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the Most Frequent Words in Disaster and Non-Disaster Tweets"
      ],
      "metadata": {
        "id": "i30Y2VQ0h3-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15,10))\n",
        "\n",
        "text = ' '.join(labled.loc[labled.target==1, 'text_clean']).lower()\n",
        "top_words_frequency_bar_plot(text,ax = ax1,plot_title='disaster')\n",
        " \n",
        "\n",
        "text = ' '.join(labled.loc[labled.target==0, 'text_clean']).lower()\n",
        "top_words_frequency_bar_plot(text,ax = ax2,plot_title='non-disaster')\n",
        " "
      ],
      "metadata": {
        "id": "Ey5G7ttvEVtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bigrams\n",
        "\n",
        "from nltk import bigrams\n",
        "\n",
        "\n",
        "def top_bigrams_frequency_bar_plot(text,ax = None,plot_title='',num_top_bigrams = 20):\n",
        "\n",
        "  tokens = word_tokenize(text)\n",
        "  \n",
        "  filtered_tokens = [w for w in tokens if (w not in STOP_WORDS) & (w.isalpha())]\n",
        "\n",
        "  # Find bigrams from filtered tokens\n",
        "  bigrams_d = list(bigrams(filtered_tokens))\n",
        "\n",
        "  # Count the frequency of each bigram\n",
        "  bigram_freq_d = FreqDist(bigrams_d)\n",
        "\n",
        "  # Convert the bigram frequency to a dataframe\n",
        "  df_bigram_freq_d = pd.DataFrame.from_dict(bigram_freq_d, orient='index', columns=['count'])\n",
        "\n",
        "  # convert the index to a string\n",
        "  df_bigram_freq_d.index = df_bigram_freq_d.index.map(lambda x: ' '.join(x))\n",
        "\n",
        "  # Sort the bigrams by count\n",
        "  df_bigram_freq_d = df_bigram_freq_d.sort_values('count',ascending=False)\n",
        "\n",
        "  # Create a bar plot of the top 20 bigrams\n",
        "  \n",
        "\n",
        "  if ax is None:\n",
        "    # Create a figure and axes object\n",
        "    fig, ax = plt.subplots(figsize=(8,6))\n",
        "\n",
        "  sns.barplot(df_bigram_freq_d.head(num_top_bigrams)['count'], df_bigram_freq_d.index[:num_top_bigrams],ax = ax)\n",
        "  ax.set_title(plot_title)"
      ],
      "metadata": {
        "id": "yXp_6RPx_KAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code creates a 2-subplot figure with bar plots of the top 15 bigrams and their frequencies for the disaster and non-disaster text data."
      ],
      "metadata": {
        "id": "K6mRwK1_iN-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(22,10))\n",
        "\n",
        "text = ' '.join(labled.loc[labled.target==1, 'text_clean']).lower()\n",
        "top_bigrams_frequency_bar_plot(text,plot_title='disaster',ax = ax1, num_top_bigrams = 15)\n",
        "\n",
        "text = ' '.join(labled.loc[labled.target==0, 'text_clean']).lower()\n",
        "top_bigrams_frequency_bar_plot(text,plot_title='non-disaster',ax = ax2, num_top_bigrams = 15)"
      ],
      "metadata": {
        "id": "lKLpY67UGvRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of the following code cell is to vectorize and convert the \"links,\" \"mentions,\" and \"hashtags\" columns of two dataframes, train and test sets into separate dataframes with one column per feature, counting the number of times each feature appears in the original data. The \"CountVectorizer\" class from the \"sklearn.feature_extraction.text\" library is used to vectorize the data."
      ],
      "metadata": {
        "id": "X2FbU8r-FinX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "# Links\n",
        "vec_links = CountVectorizer(min_df = 5, analyzer = 'word', token_pattern = r'https?://\\S+') # This vectorizer is used to count the number of times each link appears in the labled data.\n",
        "link_vec = vec_links.fit_transform(labled['links']) # This vectorizes the labled data.\n",
        "link_vec_test = vec_links.transform(unlabled['links']) # This vectorizes the unlabled data.\n",
        "X_train_link = pd.DataFrame(link_vec.toarray(), columns=vec_links.get_feature_names()) # This converts the vectorized labled data into a dataframe.\n",
        "X_test_link = pd.DataFrame(link_vec_test.toarray(), columns=vec_links.get_feature_names())  # This converts the vectorized unlabled data into a dataframe.\n",
        "\n",
        "# Mentions\n",
        "vec_men = CountVectorizer(min_df = 5)\n",
        "men_vec = vec_men.fit_transform(labled['mentions'])\n",
        "men_vec_test = vec_men.transform(unlabled['mentions'])\n",
        "X_train_men = pd.DataFrame(men_vec.toarray(), columns=vec_men.get_feature_names())\n",
        "X_test_men = pd.DataFrame(men_vec_test.toarray(), columns=vec_men.get_feature_names())\n",
        "\n",
        "# Hashtags\n",
        "vec_hash = CountVectorizer(min_df = 5)\n",
        "hash_vec = vec_hash.fit_transform(labled['hashtags'])\n",
        "hash_vec_test = vec_hash.transform(unlabled['hashtags'])\n",
        "X_train_hash = pd.DataFrame(hash_vec.toarray(), columns=vec_hash.get_feature_names())\n",
        "X_test_hash = pd.DataFrame(hash_vec_test.toarray(), columns=vec_hash.get_feature_names())\n",
        "print (X_train_link.shape, X_train_men.shape, X_train_hash.shape)"
      ],
      "metadata": {
        "id": "N8KENpsHFjkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code creates a bar plot of the top 15 most frequent link features in the data"
      ],
      "metadata": {
        "id": "2zffPxxhmMqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train_link.sum()\n",
        "num_to_display = 15\n",
        "\n",
        "ascending = False\n",
        "X = X.sort_values( ascending=ascending).head(num_to_display)\n",
        "\n",
        "# plot the top column_name using seaborn\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "\n",
        "sns.barplot(x= X , y =X.index,ax = ax)\n",
        " \n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qkVz5INT5pA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code creates a bar plot of the top 15 most frequent mention features in the data"
      ],
      "metadata": {
        "id": "1VVga7F8mQ9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train_men.sum()\n",
        "X = X.drop('no') #no is overwhelmingly common so we drop it for sake of analysis\n",
        "num_to_display = 15\n",
        "\n",
        "\n",
        "X = X.sort_values( ascending=ascending).head(num_to_display)\n",
        "\n",
        "# plot the top column_name using seaborn\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "\n",
        "sns.barplot(x= X , y =X.index,ax = ax)\n",
        " \n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "acSELpS051le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code creates a bar plot of the top 15 most frequent hashtag features in the data"
      ],
      "metadata": {
        "id": "S4m7qqc2mT9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train_hash.sum()\n",
        "X = X.drop('no') #no is overwhelmingly common so we drop it for sake of analysis\n",
        "num_to_display = 15\n",
        "\n",
        "\n",
        "X = X.sort_values( ascending=ascending).head(num_to_display)\n",
        "\n",
        "# plot the top column_name using seaborn\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "\n",
        "sns.barplot(x= X , y =X.index,ax = ax)\n",
        " \n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OlU19Efw51tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we examine the fraction of disaster tweets for each feature. In particular, a bar plot is generated to visualize the ratio of disaster tweets to all tweets for each feature (such as links, mentions, and hashtags) based on the training data."
      ],
      "metadata": {
        "id": "QsW3Qb6hqEZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train_link\n",
        "num_to_display = 50\n",
        "\n",
        "# Compute the ratio of disaster tweets to all tweets for each link\n",
        "disaster_ratio = (X.transpose().dot(labled['target']) / X.sum(axis=0)).sort_values(ascending=False)\n",
        "\n",
        "# Create a bar plot to visualize the results\n",
        "plt.figure(figsize=(20,15))\n",
        "disaster_ratio = disaster_ratio[:num_to_display]\n",
        "\n",
        "sns.barplot(x=disaster_ratio, y=disaster_ratio.index)\n",
        "\n",
        "# Add a line to indicate the average ratio across all links\n",
        "plt.axvline(np.mean(labled.target))\n",
        "\n",
        "plt.title('% of disaster tweet')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "C464jAzpUWus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train_men\n",
        "num_to_display = 50\n",
        "\n",
        "# Compute the ratio of disaster tweets to all tweets for each link\n",
        "disaster_ratio = (X.transpose().dot(labled['target']) / X.sum(axis=0)).sort_values(ascending=False)\n",
        "\n",
        "# Create a bar plot to visualize the results\n",
        "plt.figure(figsize=(20,15))\n",
        "disaster_ratio = disaster_ratio[:num_to_display]\n",
        "\n",
        "sns.barplot(x=disaster_ratio, y=disaster_ratio.index)\n",
        "\n",
        "# Add a line to indicate the average ratio across all links\n",
        "plt.axvline(np.mean(labled.target))\n",
        "\n",
        "plt.title('% of disaster tweet')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tIfFCu0nVTd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train_hash\n",
        "num_to_display = 100\n",
        "\n",
        "# Compute the ratio of disaster tweets to all tweets for each link\n",
        "disaster_ratio = (X.transpose().dot(labled['target']) / X.sum(axis=0)).sort_values(ascending=False)\n",
        "\n",
        "# Create a bar plot to visualize the results\n",
        "plt.figure(figsize=(20,15))\n",
        "disaster_ratio = disaster_ratio[:num_to_display]\n",
        "\n",
        "sns.barplot(x=disaster_ratio, y=disaster_ratio.index)\n",
        "\n",
        "# Add a line to indicate the average ratio across all links\n",
        "plt.axvline(np.mean(labled.target))\n",
        "\n",
        "plt.title('% of disaster tweet')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ma9W1Pz48xc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next code cell performs TF-IDF transformation on the training and test sets text data using a TfidfVectorizer with both single words and bi-grams."
      ],
      "metadata": {
        "id": "UWaCWZxjtnfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tf-idf for text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# initialize TfidfVectorizer with minimum document frequency of 10, n-gram range of (1,2) and stop words in english\n",
        "vec_text = TfidfVectorizer(min_df = 10, ngram_range = (1,2), stop_words='english') \n",
        "\n",
        "# fit the vectorizer to the labeled text data and transform it\n",
        "text_vec = vec_text.fit_transform(labled['text_clean'])\n",
        "# transform the unlabeled text data using the fitted vectorizer\n",
        "text_vec_test = vec_text.transform(unlabled['text_clean'])\n",
        "\n",
        "# create a dataframe for the transformed labeled text data using the feature names from the vectorizer\n",
        "X_train_text = pd.DataFrame(text_vec.toarray(), columns=vec_text.get_feature_names())\n",
        "\n",
        "# create a dataframe for the transformed unlabeled text data using the feature names from the vectorizer\n",
        "X_test_text = pd.DataFrame(text_vec_test.toarray(), columns=vec_text.get_feature_names())\n",
        "\n",
        "# print the shape of the training text dataframe\n",
        "print (X_train_text.shape)\n"
      ],
      "metadata": {
        "id": "oJZkUWx8VYa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining the dataframes together\n",
        "labled_ext = labled.copy()\n",
        "unlabled_ext = unlabled.copy()\n",
        "\n",
        "labled_ext = labled_ext.join(X_train_link, rsuffix='_link')\n",
        "labled_ext = labled_ext.join(X_train_men, rsuffix='_mention')\n",
        "labled_ext = labled_ext.join(X_train_hash, rsuffix='_hashtag')\n",
        "labled_ext = labled_ext.join(X_train_text, rsuffix='_text')\n",
        "unlabled_ext = unlabled_ext.join(X_test_link, rsuffix='_link')\n",
        "unlabled_ext = unlabled_ext.join(X_test_men, rsuffix='_mention')\n",
        "unlabled_ext = unlabled_ext.join(X_test_hash, rsuffix='_hashtag')\n",
        "unlabled_ext = unlabled_ext.join(X_test_text, rsuffix='_text')\n",
        "print (labled_ext.shape, unlabled_ext.shape)"
      ],
      "metadata": {
        "id": "hPQsPhPFVhBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# We drop the columns that we don't need for our model.\n",
        "features_to_drop = ['id', 'keyword','location','text','location','text_clean', 'hashtags', 'mentions','links']\n",
        "\n",
        "# We drop the target column from the labled data set (since it is the column that we want to predict).\n",
        "X_labled = labled_ext.drop(columns = features_to_drop + ['target'])\n",
        "X_unlabled= unlabled_ext.drop(columns = features_to_drop)\n",
        "\n",
        "Y_labled = labled_ext.target\n"
      ],
      "metadata": {
        "id": "Dh1tE08db7Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(X_labled.values, Y_labled, \n",
        "                                                  stratify=labled.target.values, \n",
        "                                                  random_state=23, \n",
        "                                                  test_size=0.1, shuffle=True)"
      ],
      "metadata": {
        "id": "_NJKhVsWb9ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "_kKSu7fY1KC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (x_train.shape)\n",
        "print (x_valid.shape)"
      ],
      "metadata": {
        "id": "jg5Kz_GzcPZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# F-1 score\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "metadata": {
        "id": "7C_RGmkNK12G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def  get_performance_metrics(pipeline,x_train, x_valid, y_train, y_valid):\n",
        "  print('-'*20)\n",
        "  print ('Training accuracy: %.4f' % pipeline.score(x_train, y_train))\n",
        "  print ('Validation accuracy: %.4f' % pipeline.score(x_valid, y_valid))\n",
        "  print ('Training f-1 score: %.4f' % f1_score(y_train, pipeline.predict(x_train)))\n",
        "  print ('Validation f-1 score: %.4f' % f1_score(y_valid, pipeline.predict(x_valid)))\n",
        "  print(pd.DataFrame(confusion_matrix(y_train, pipeline.predict(x_train))))"
      ],
      "metadata": {
        "id": "DeKtuOeTPUEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection and Evaluation\n",
        "\n",
        "Select and train several models using the prepared data, such as logistic regression, Naive Bayes, Random Forest, etc. Use cross-validation to evaluate the performance of the models and to select the best model.\n",
        "\n",
        "Perform k-fold cross-validation: In the next section, use the cross_val_score function from scikit-learn's model_selection module to perform k-fold cross-validation. You can use the feature matrix and target variable obtained in step 3 as input, and specify the number of folds, the model, and the evaluation metric as parameters."
      ],
      "metadata": {
        "id": "zElcrAG-Fl2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Target encoding\n",
        "\"\"\"\n",
        "# Declare the columns to be encoded\n",
        "features = ['keyword','location']\n",
        "\n",
        "# Initialize the encoder\n",
        "encoder = ce.TargetEncoder(cols=features)\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "# Fit the encoder to the labeled dataset\n",
        "encoder.fit(labled[features],labled['target'])\n",
        "\n",
        "# Apply the encoding to the labeled dataset\n",
        "labled = labled.join(encoder.transform(labled[features]).add_suffix('_target'))\n",
        "\n",
        "# Apply the encoding to the unlabeled dataset\n",
        "unlabled = unlabled.join(encoder.transform(unlabled[features]).add_suffix('_target'))\n",
        "\"\"\"\n",
        "\n",
        "def run_kfold_training(pipeline,X_labled, Y_labled):\n",
        "  #kf = KFold(n_splits=10, shuffle=True, random_state=149)\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=149)\n",
        "  scores = []\n",
        "\n",
        "\n",
        "  for train_index, val_index in skf.split(X_labled.values, Y_labled): #kf.split(X_labled.values, Y_labled):\n",
        "      \"\"\"\n",
        "      df = X_labled.copy()\n",
        "       \n",
        "      # Fit the encoder to the labeled dataset\n",
        "      encoder.fit(labled[features].iloc[train_index],labled['target'].iloc[train_index])\n",
        "      \n",
        "      df = df.join(encoder.transform(labled[features]).add_suffix('_target'))\n",
        "    \"\"\"\n",
        "      #encoder.transform(labled[features].iloc[train_index])\n",
        "      #encoder.transform(labled[features].iloc[val_index])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      #x_train = X_labled.values[train_index]\n",
        "      #x_valid = X_labled.values[val_index]\n",
        "      #y_train = Y_labled[train_index]\n",
        "      #y_valid = Y_labled[val_index]\n",
        "      x_train, x_valid = X_labled.values[train_index], X_labled.values[val_index]\n",
        "      y_train, y_valid = Y_labled[train_index], Y_labled[val_index]\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "      pipeline.fit(x_train, y_train)\n",
        "      y_pred = pipeline.predict(x_valid)\n",
        "      score = accuracy_score(y_valid, y_pred)\n",
        "      get_performance_metrics(pipeline,x_train, x_valid, y_train, y_valid)\n",
        "      scores.append(score)\n",
        "      \n",
        "  print(\"Cross validation scores: \", scores)\n",
        "  print(\"Mean cross validation score: \", np.mean(scores))"
      ],
      "metadata": {
        "id": "D22h-Mh6c6aW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cy6E5sj3NWCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "lr = LogisticRegression(C = 0.6,solver='liblinear', penalty = 'l2', random_state=129) # Other solvers have failure to converge problem\n",
        "pipeline = Pipeline([('scale',scaler), ('lr', lr),])\n",
        "\n",
        "run_kfold_training(pipeline,X_labled, Y_labled)"
      ],
      "metadata": {
        "id": "iw27PDFxdFH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "low = 0.25\n",
        "high = 0.5\n",
        "steps = 10\n",
        " \n",
        "param_grid = {\n",
        "    'lr__C': [low + k*(high-low)/steps for k in range(steps)],\n",
        "    #'lr__penalty': ['l1', 'l2', 'none']\n",
        "    #'lr__solver': ['newton-cg']\n",
        "}\n",
        "\n",
        "# 'newton-cg' , 'lbfgs', 'sag'\n",
        "\n",
        "# Use GridSearchCV to find the best regularization strength\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Get the best regularization strength\n",
        "best_C = grid_search.best_params_['lr__C']\n",
        "#best_solver = grid_search.best_params_['lr__solver']\n",
        "#best_penalty = grid_search.best_params_['lr__penalty']\n",
        "\n",
        "# Retrain the model using the best regularization strength\n",
        "lr = LogisticRegression(C=best_C, penalty = 'l2', solver='lbfgs', random_state=129)\n",
        "pipeline = Pipeline([('scale',scaler), ('lr', lr),])\n",
        "pipeline.fit(x_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "iV7rx9SfdLQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimenting with Other Models"
      ],
      "metadata": {
        "id": "TxwYq9lv28Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of a base classifier\n",
        "dt = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "# Create an instance of AdaBoostClassifier\n",
        "adb = AdaBoostClassifier(base_estimator=dt, n_estimators=100)\n",
        "\n",
        "\n",
        "pipeline = Pipeline([('scale',scaler), ('adb', adb)])\n",
        " \n",
        "\n",
        "run_kfold_training(pipeline,X_labled, Y_labled)"
      ],
      "metadata": {
        "id": "stBldF43QTzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ada Boosting"
      ],
      "metadata": {
        "id": "kdoBozdHR6XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "lr = LogisticRegression(C = 0.5, random_state=129) # Other solvers have failure to converge problem # ,solver='liblinear', penalty = 'l1'\n",
        "\n",
        "# Create an instance of AdaBoostClassifier\n",
        "adb = AdaBoostClassifier(base_estimator=lr, n_estimators=100)\n",
        "\n",
        "pipeline = Pipeline([('scale',scaler), ('adb', adb)])\n",
        " \n",
        "\n",
        "run_kfold_training(pipeline)"
      ],
      "metadata": {
        "id": "0U1T7jJnQmmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "ee_09t-2S4K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "gbc = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "pipeline = Pipeline([('scale',scaler), ('gbc', gbc)])\n",
        " \n",
        "\n",
        "#pipeline.fit(x_train,y_train)\n",
        " \n",
        "run_kfold_training(pipeline)"
      ],
      "metadata": {
        "id": "IWUo8I2ES3l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Performance of the Model\n",
        " In the next section, use the scores obtained from the cross-validation to evaluate the performance of the model. You can use the mean and standard deviation of the scores to get an estimate of the performance of the model.\n",
        "\n",
        "Hyperparameter tuning: Fine-tune the selected model by searching for the best hyperparameters using techniques like GridSearchCV or RandomizedSearchCV.\n",
        "\n",
        "Hyperparameter tuning: If the performance of the model is not satisfactory, use techniques like GridSearchCV or RandomizedSearchCV to fine-tune the model by searching for the best hyperparameters."
      ],
      "metadata": {
        "id": "tFv2TleuFowM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_performance_metrics(pipeline,x_train, x_valid, y_train, y_valid)"
      ],
      "metadata": {
        "id": "ukfgbPaUe3mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline"
      ],
      "metadata": {
        "id": "4z0QfL0ch939"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model on the entire data set**"
      ],
      "metadata": {
        "id": "vjSY1MeTD2Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_labled.values, Y_labled)"
      ],
      "metadata": {
        "id": "ws5pT6AtDx3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_performance_metrics(pipeline,x_train, x_valid, y_train, y_valid)"
      ],
      "metadata": {
        "id": "W3NUmYQdFHiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlabled_hand_labled = unlabled.copy()"
      ],
      "metadata": {
        "id": "dYM3sabmjdpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = np.random.randint(0,len(unlabled_hand_labled))\n",
        "print(unlabled_hand_labled.iloc[index].text)\n",
        "print(submit.target[index])"
      ],
      "metadata": {
        "id": "ZCtDtK-ejo71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Submission**"
      ],
      "metadata": {
        "id": "imkdT-AGEHHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = pipeline.predict(X_unlabled.values)\n",
        "\n",
        "submit = sample.copy()\n",
        "submit.target = y_test\n",
        "submit.to_csv('submit_maybe_better.csv',index=False)"
      ],
      "metadata": {
        "id": "j2oP2TdMDl3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Run the following if you want to submit now otherwise continue to the next section to try to refine the model***"
      ],
      "metadata": {
        "id": "SQZ4CobSKMe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions submit -c nlp-getting-started -f submit_maybe_better.csv -m \"Message\""
      ],
      "metadata": {
        "id": "YcXLEz2WKH26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Approach"
      ],
      "metadata": {
        "id": "-q2aX63zjclO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To keep things nice an neat we copy over some of the interesting features into a new dataframe. "
      ],
      "metadata": {
        "id": "6gU_tSu2jw4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this context `dl` will stand for deep learning. We recall the correlations between the various features. "
      ],
      "metadata": {
        "id": "8otDaJoDnUHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It would seem that only the `text_len` and `stop_word_count` appear to be correlated with the features. We will leave them all for now.\n"
      ],
      "metadata": {
        "id": "nWg-Fp4Pnj-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labled.columns"
      ],
      "metadata": {
        "id": "NOCFxvIOrbQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labled_dl =labled[['keyword','location','text_clean','stop_word_count','text_len','hashtags','target']]\n",
        "unlabled_dl = unlabled[['keyword','location','text_clean','stop_word_count','text_len','hashtags']]"
      ],
      "metadata": {
        "id": "qpDNv-o6nDb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labled_dl.corr()['target'].drop('target').sort_values()"
      ],
      "metadata": {
        "id": "nbJflr0tnKK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labled_dl.keyword = labled_dl.keyword.fillna('no')\n",
        "unlabled_dl.keyword = unlabled_dl.keyword.fillna('no')\n",
        "\n",
        "labled_dl.location = labled_dl.location.fillna('no')\n",
        "unlabled_dl.location = unlabled_dl.location.fillna('no')"
      ],
      "metadata": {
        "id": "lG-Cih9aqqbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labled_dl.head(10)"
      ],
      "metadata": {
        "id": "ac3OlUEbyLgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "# We drop the columns that we don't need for our model.\n",
        "features_to_drop = []\n",
        "\n",
        "# We drop the target column from the labled data set (since it is the column that we want to predict).\n",
        "X_labled = labled_dl.drop(columns = features_to_drop + ['target'])\n",
        "X_unlabled= unlabled_dl.drop(columns = features_to_drop)\n",
        "\n",
        "Y_labled = labled_ext.target"
      ],
      "metadata": {
        "id": "a-42DEDoxwbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_labled.head(10)"
      ],
      "metadata": {
        "id": "x_u06PVhwrP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create at train-test split of the labeled datasets"
      ],
      "metadata": {
        "id": "SgH_O7NzxflI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import text\n",
        "# using keras tokenizer here\n",
        "token = text.Tokenizer(num_words=None)\n",
        "\n",
        "\n",
        "relavent_text_data = [];\n",
        "\n",
        "features = ['keyword' , 'location', 'text_clean','hashtags']\n",
        "for f in features:\n",
        "  relavent_text_data += list(X_labled[f])\n",
        "  relavent_text_data += list(X_unlabled[f])\n",
        "\n",
        "token.fit_on_texts(relavent_text_data)\n",
        "word_index = token.word_index\n"
      ],
      "metadata": {
        "id": "-wtJwKkYddik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_labled.text_clean"
      ],
      "metadata": {
        "id": "5OPvJpi8I6Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(list(labled_dl.text_clean.apply(lambda x : len(x))));"
      ],
      "metadata": {
        "id": "2nDcmoutHtCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the tokenized sentences"
      ],
      "metadata": {
        "id": "KYVKiSPNKL5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(df,feature,padding_len):\n",
        "  X = token.texts_to_sequences(df[feature])\n",
        " \n",
        "  # zero pad the sequences\n",
        "  X_pad = pad_sequences(X, maxlen=padding_len)\n",
        "  \n",
        "  for i in range(padding_len):\n",
        "      df[feature +'_' + str(i)] = [x[i] for x in X_pad]\n"
      ],
      "metadata": {
        "id": "HmNXDZlqKrJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 120\n",
        "tokenizer(X_labled,'text_clean',max_len)\n",
        "tokenizer(X_unlabled,'text_clean',max_len)\n",
        "\n",
        "tokenizer(X_labled,'keyword',1)\n",
        "tokenizer(X_unlabled,'keyword',1)\n",
        "\n",
        "\n",
        "tokenizer(X_labled,'location',1)\n",
        "tokenizer(X_unlabled,'location',1)\n",
        "\n",
        "tokenizer(X_labled,'hashtags',1)\n",
        "tokenizer(X_unlabled,'hashtags',1)"
      ],
      "metadata": {
        "id": "lY19W3-3LSw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the tokenized keyword "
      ],
      "metadata": {
        "id": "Ct9U5FA8KPDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We drop the columns that we don't need for our model.\n",
        "features_to_drop = ['keyword'\t,'location',\t'text_clean'\t, 'hashtags']\n",
        "\n",
        "# We drop the target column from the labled data set (since it is the column that we want to predict).\n",
        "X_labled = X_labled.drop(columns = features_to_drop)\n",
        "X_unlabled= X_unlabled.drop(columns = features_to_drop)\n",
        " "
      ],
      "metadata": {
        "id": "b1ACKCRtCrSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_labled.head(10)"
      ],
      "metadata": {
        "id": "4elJmu3wC_g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(X_labled.values, Y_labled, \n",
        "                                                  stratify=Y_labled, \n",
        "                                                  random_state=23, \n",
        "                                                  test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "mUkxNI2Zm-Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (x_train.shape)\n",
        "print (x_valid.shape)"
      ],
      "metadata": {
        "id": "Vp6469GWm-Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings\n",
        "\n",
        "To import the vectors I found this [link](https://stackoverflow.com/questions/50060241/how-to-use-glove-word-embeddings-file-on-google-colaboratory) which explained everything. Including how to even save the vectors in your drive for later use. "
      ],
      "metadata": {
        "id": "aWtfYdkDS9KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "id": "A4si6h0HRgf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove*.zip"
      ],
      "metadata": {
        "id": "0UC0CKl-TBxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!pwd"
      ],
      "metadata": {
        "id": "xukYno_xTG40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file 'glove.6B.300d.txt' with utf-8 encoding\n",
        "f = open('glove.6B.300d.txt', encoding='utf-8')\n",
        "\n",
        "# Create an empty dictionary to store the word vectors\n",
        "embeddings_index = {}\n",
        "\n",
        "# Use tqdm to display a progress bar while iterating through the file\n",
        "for line in tqdm(f):\n",
        "    # Split the line by space and store the values in a list\n",
        "    values = line.strip().split(' ')\n",
        "    \n",
        "    # The first value in the list is the word\n",
        "    word = values[0]\n",
        "    \n",
        "    # The rest of the values represent the coefficients of the word vector, which are stored as a numpy array\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    \n",
        "    # Add the word vector to the dictionary\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "# Print the number of word vectors found\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "id": "ZyUtKUQ01-aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an embedding matrix for the words we have in the dataset\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "JUcdbpErcbAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Models"
      ],
      "metadata": {
        "id": "7DC6KNFgoXl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n"
      ],
      "metadata": {
        "id": "FiEzEo0aj0yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A simple LSTM with glove embeddings and two dense layers\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=x_train.shape[1],\n",
        "                     trainable=False))\n",
        "\n",
        "model.add(tf.keras.layers.SpatialDropout1D(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.LSTM(100, dropout=0.3, recurrent_dropout=0.3,return_sequences=True))\n",
        "\n",
        "model.add(tf.keras.layers.LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.8))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.8))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics =['accuracy',f1_score])\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
      ],
      "metadata": {
        "id": "RDQBMsyLHyqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the early stopping\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    min_delta=0, \n",
        "    patience=8, \n",
        "    verbose=0, \n",
        "    mode='auto'\n",
        ")\n",
        "\n",
        "model.fit(x_train , y_train, batch_size=128, \n",
        "          epochs=100, verbose=1, \n",
        "          validation_data=(x_valid, y_valid), callbacks =[earlystop])\n",
        " "
      ],
      "metadata": {
        "id": "870zljgBeYmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "sJrFuoWkoZle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = tf.keras.models.load_model(\"model.h5\")\n"
      ],
      "metadata": {
        "id": "1KcskB5_mI96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_train)\n",
        "predictions = predictions.flatten()"
      ],
      "metadata": {
        "id": "9Ajpn_zLPklu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "W502p6UJPwfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maximize F1"
      ],
      "metadata": {
        "id": "adEOQdqlOuAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute the precision, recall, and threshold values for different thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_train, predictions)\n",
        "\n",
        "# Compute the F1 score for each threshold\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Plot the F1 score vs. threshold\n",
        "plt.plot(thresholds, f1[:-1], color='darkorange', lw=2, label='F1 score')\n",
        "\n",
        "# Set the x and y limits of the plot\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "# Label the x and y axis\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('F1 score')\n",
        "\n",
        "# Give the plot a title\n",
        "plt.title('F1 score vs. threshold')\n",
        "\n",
        "# Add the legend to the plot\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Find the optimal threshold (the threshold that maximizes the F1 score)\n",
        "optimal_idx = np.argmax(f1[:-1])\n",
        "optimal_threshold = thresholds[optimal_idx]\n"
      ],
      "metadata": {
        "id": "Ya5bXY3gOxXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_threshold"
      ],
      "metadata": {
        "id": "WBMfnCKWO-5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(Y_labled, predictions)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n"
      ],
      "metadata": {
        "id": "4OuQzcmtPfFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_threshold"
      ],
      "metadata": {
        "id": "z2Kbib1HSJrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max Accuracy"
      ],
      "metadata": {
        "id": "GiRNyKiCOol5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute the ROC curve, which is a graph showing the true positive rate vs. false positive rate\n",
        "fpr, tpr, thresholds = roc_curve(y_train, predictions)\n",
        "\n",
        "# Compute the area under the curve (AUC) of the ROC\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "\n",
        "# Plot the diagonal line (representing random guess)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "\n",
        "# Set the x and y limits of the plot\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "# Label the x and y axis\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n",
        "# Give the plot a title\n",
        "plt.title('Receiver operating characteristic example')\n",
        "\n",
        "# Add the legend to the plot\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Find the optimal threshold (the threshold that maximizes the difference between true positive rate and false positive rate)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]"
      ],
      "metadata": {
        "id": "JspaowNAROBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_unlabled.values)"
      ],
      "metadata": {
        "id": "az8T4wQeEdu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_threshold"
      ],
      "metadata": {
        "id": "iYhA56z7Rh4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_bool = ( predictions > optimal_threshold ) + 0\n",
        "predictions_bool = predictions_bool.flatten()"
      ],
      "metadata": {
        "id": "I3BgFtAxFBQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_bool = ( predictions > 0.5 ) + 0\n",
        "predictions_bool = predictions_bool.flatten()"
      ],
      "metadata": {
        "id": "yNnEa6U-KjxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_bool[:15]"
      ],
      "metadata": {
        "id": "Ge1wZVsxOOAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create submission"
      ],
      "metadata": {
        "id": "T-eIKejYFv3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submit = sample.copy()\n",
        "submit.target = predictions_bool\n",
        "submit.to_csv('lstm_120_token_length.csv',index=False)"
      ],
      "metadata": {
        "id": "Y-y6GfYcF4ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Run the following if you want to submit now otherwise continue to the next section to try to refine the model***"
      ],
      "metadata": {
        "id": "vV0MueR2GBeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions submit -c nlp-getting-started -f lstm_120_token_length.csv -m \"Message\""
      ],
      "metadata": {
        "id": "-uk8OYVTGBeb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}